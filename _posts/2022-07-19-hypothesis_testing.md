---
layout: post
title: "Hypothesis Testing"
author: Cetus Li
date: 2022-07-19
---

#### **假设检验（Hypothesis Testing）**
- 零假设（Null Hypothesis）对应消极的态度，认为数据之间没有差异，数据间的差异是随机产生的没有意义的结果。
- 备择假设（Alternative Hypothesis）对应积极的态度，认为数据间有差异。
- 同样的数据，两个假设给出了不同的看法。 计算零假设为真时该结果出现的概率，如果极小，就拒绝零假设，同时接受备择假设。
- 如果零假设下的概率不是极小概率，则分不出胜负，不接受任何一个假设。
- 对于只关心实际操作，对错误有包容性的情况，达到显著性就拒绝，否则不拒绝，且不关心显著性程度。
- 对于科学研究，即使显著性不够无法拒绝，也可根据显著性程度获得初步判断并实行进一步实验验证，直到找到可以显著性说明差异的证据。


#### **显著性检验（Significance Testing）**
- 零假设为真时该结果出现的概率低于多少可以拒绝零假设？常用两个标准，0.05 和 0.01 ，也叫显著性水平（significance level）或者 $\alpha$ 水平。
- 当概率值低于 $\alpha$ 水平时，认为零假设错误，并拒绝零假设，接受备择假设，差异具有统计显著性。
- 在零假设下，数据结果发生的概率小，虽然可以假定零假设错误而拒绝它，但实际上仍然存在极小的概率零假设是正确的，差异的确是随机产生的。
- 从理论上讲，显著性检验存在两种错误：I，零假设虽然被拒绝但其实是正确的（Type I error）；II，零假设错误但因为没有通过显著性检验无法拒绝（Type II error）。
- Type I error 是真的错误。
- Type II error 不是真的错误，这种结果是差异的显著性不够造成的。

**正确地拒绝错误的零假设的概率称作有效度（Power），等于$1-\beta$ ，$\beta$ 是零假设错误却没能成功拒绝（Type II error）的概率。**

在科学研究中，双尾检验比单尾检验更为常见。

#### **学生化范围检验（Studentized Range Distribution and Tukey HSD test）**
当需要比较多个条件相互之间的差异时，比如有 4 个实验条件就需要 6 种两两比较，比较结果中出现 I 型错误的概率会随着条件数目的增多而增大。（当条件数目为 12 时， I 型错误的概率已经达到 0.70）。为了控制  I 型错误的影响，使用 T 分布的变种分布 Studentized Range Distribution 来进行检验，这种检验叫做 Tukey Honestly Significant Difference Test 或者 Tukey HSD Test。Tukey HSD Test 的计算方法：
1. Studentized Range Distribution 除了自由度参数外还需要条件个数作为参数。
2. 仍然假设数据正态分布、均匀方差、独立抽样。零假设是各个条件的均值都相等，均值之差值为 0 。
3. 计算各个条件的均值和方差。方差按条件个数取平均作为估计的总体方差。如果各个条件的样本量不相等，平均方差的计算为各自与自己均值的距离平方之总和除以自由度（总样本个数-条件个数）。
4. 两两比较的 t 值计算变为 Q 值计算，公式为 $Q=\frac{M_{i}-M_{j}}{\sqrt{\frac{MSE}{n}}}$ ，MSE 是上一步计算的总体方差的估计，n 是每个条件下数据的个数。
5. 自由度 df=条件个数乘以n - 条件个数。
6. 使用 Q 值、自由度df、条件个数，在 Studentized Range Distribution 中得到对应的概率，并与显著水平 $\alpha$ 比较。

#### **具体统计量的检验**
假如有 24 个实验对象，按实验条件分为 4 组，每组 6 个实验对象。每组的实验结果数据：均值和方差分别是是 $M_{i}$ 和 $S_{i}$ ，$i\in(1,2,3,4)$。我想知道实验一加上实验三的数据和实验二加上实验四的数据之间有没有明细差异，我指定了一个具体的统计量 L=（$M_{1}+M_{3}$）-（$M_{2}+M_{4}$）=$M_{1}-M_{2}+M_{3}-M_{4}$，零假设 $H_{0}$: L=0。指定统计量 L 等于有关的各项统计量乘以一个系数后的加和。这里的系数分别是 1，-1,1，-1。

$$L=\Sigma (c_{i}M_{i})$$

使用 t 分布计算概率进行检验。这种情况 t 值计算公式是：

$$t=\frac{L}{\sqrt{\frac{\Sigma c_{i}^{2}\bar{S}}{n}}} $$

$\Sigma c_{i}^{2}$ 是各个系数的平方和，$\bar{S}$ 是四个实验条件的方差的平均值，n 是每个实验条件下实验对象的个数，这里 n=6，如果四个实验中实验对象个数不等，取他们的调和平均数。使用 t 分布时还需要知道自由度，这里 df = 全部实验对象个数 - 实验组别个数 = 24 - 4 = 20 ，计算概率后与显著水平 $\alpha$ 比较。如果四个条件的结果不是独立的，把 L 的方差，也就是 $\Sigma c_{i}^{2}\bar{S}$ 替换成含有相关系数的相关变量的方差和公式。

#### **Bonferroni不等式（Bonferroni Inequality）**
每一个差异比较的显著性检验都有自己的 I 型错误率 $\alpha$。如果我的实验里需要做 c 个比较的差异检验，我的实验里出现 I 型错误的概率 F 显然高于单个差异比较出现 I 型错误的概率 $\alpha$ ，因为任何一个比较发生 I 型错误，我的实验都产生 I 型错误。在 c 较小的情况下，实验的 I 型错误率和单个比较的 I 型错误率具有下面的关系：

$$F\le c\alpha$$

实际上，计算时都近似处理为 $F=c\alpha$ ，如果要控制实验的 I 型错误率为 $\alpha$  的话，单个比较的 I 型错误率就需要控制在 $\alpha/c$ 以下，虽然可以控制实验的 I 型错误率，但是也降低了实验的有效度 Power。


